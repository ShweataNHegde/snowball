{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7406d4f-5e42-492e-aaaf-6427d94d93eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import pathlib\n",
    "import yake\n",
    "import subprocess\n",
    "import logging\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad04b9-89b8-499b-b7b7-2c876ce95548",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "# All the functions\n",
    "def querying_pygetpapers_sectioning(query, hits, output_directory, using_terms = False, terms_txt=None):\n",
    "    \"\"\"queries pygetpapers for specified query. Downloads XML, and sections papers using ami section\n",
    "\n",
    "    Args:\n",
    "        query (str): query to pygetpapers\n",
    "        hits (int): no. of papers to download\n",
    "        output_directory (str): CProject Directory (where papers get downloaded)\n",
    "        using_terms (bool, optional): pygetpapers --terms flag. Defaults to False.\n",
    "        terms_txt (str, optional): path to text file with terms. Defaults to None.\n",
    "    \"\"\"\n",
    "    logging.info('querying pygetpapers')\n",
    "    if using_terms:\n",
    "        subprocess.run(f'pygetpapers -q \"{query}\" -k {hits} -o {output_directory} -x --terms {terms_txt}',\n",
    "                                shell=True)\n",
    "    else:  \n",
    "        subprocess.run(f'pygetpapers -q \"{query}\" -k {hits} -o {output_directory} -x', \n",
    "                                shell=True)\n",
    "    logging.info('running ami section')\n",
    "    subprocess.run(f'ami -p {output_directory} section', shell=True)\n",
    "\n",
    "def parse_xml(output_directory, results_txt, body_section='figure'):\n",
    "    \"\"\"globs the specified section parsed xml and dumps the text to a file\n",
    "\n",
    "    Args:\n",
    "        output_directory (str): CProject directory\n",
    "        results_txt (str):name of text file to write parsed XML\n",
    "        body_section (str, optional): [description]. Defaults to 'method'.\n",
    "    \"\"\"\n",
    "    WORKING_DIRECTORY = os.getcwd()\n",
    "    glob_results = glob.glob(os.path.join(WORKING_DIRECTORY,\n",
    "                                          output_directory,\"*\", \"sections\",\n",
    "                                          \"**\", f\"*{body_section}*.xml\"), recursive = True)\n",
    "    logging.info(f'globbed_xml: {glob_results}')\n",
    "    file1 = open(results_txt,\"w+\", encoding='utf-8')\n",
    "    for result in glob_results:\n",
    "        tree = ET.parse(result)\n",
    "        root = tree.getroot()\n",
    "        xmlstr = ET.tostring(root, encoding='utf8', method='xml')\n",
    "        soup = BeautifulSoup(xmlstr, features='lxml')\n",
    "        text = soup.get_text(separator=\"\")\n",
    "        text = text.replace(\n",
    "            '\\n', '')\n",
    "        print(text, file = file1)\n",
    "    logging.info(f'wrote text to {results_txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed080f-7b4d-4245-8b79-07f74b783507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_phrase_extraction(results_txt, terms_txt):\n",
    "    \"\"\"extract key phrases from the text file with parsed xml and saves the phrases in a text file (comma-separated)\n",
    "\n",
    "    Args:\n",
    "        results_txt (str): text file with parsed XML text\n",
    "        terms_txt (str): name of text file with comma-separated extracted key phrases\n",
    "    \"\"\"\n",
    "    text = pathlib.Path(results_txt).read_text(encoding='utf-8')\n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan='en', n=2, top=50, features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    keywords_list = []\n",
    "    for kw in keywords:\n",
    "        keywords_list.append(kw[0])\n",
    "    logging.info('extracted key phrases')\n",
    "    \n",
    "    keywords_list_string = ', '.join(str(i) for i in keywords_list)\n",
    "    with open(terms_txt, 'w', encoding='utf-8') as fo:\n",
    "        fo.write(keywords_list_string)\n",
    "    logging.info(f'wrote the phrases to {terms_txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f4f4c-bc17-4f9f-9b4a-da7add538eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
